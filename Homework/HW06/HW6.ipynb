{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science â€“ Homework 6\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "Due: Friday, March 01 2024, 11:59pm.\n",
    "\n",
    "In Part 1 of this homework you will scrape github repositories and organize the information in a Pandas dataframe. In Part 2, you will use linear regression to gain meaningful insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Data\n",
    "First Name: Logan\n",
    "<br>\n",
    "Last Name: Correa\n",
    "<br>\n",
    "E-mail: u1094034@umail.utah.edu\n",
    "<br>\n",
    "UID: u1094034\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup \n",
    "from bs4 import BeautifulSoup\n",
    "# you can use either of these libraries to get html from a website\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) \n",
    "# where the data is stored\n",
    "DATA_PATH = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape Github Repository List using BeautifulSoup\n",
    "In this part you will explore Github repositories, specifically the 100 most-starred repositories. You are going to scrape data from a snapshot of [this repository list](https://github.com/search?o=desc&q=stars%3A%3E1&s=stars&type=Repositories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Check whether you are permitted to scrape the data\n",
    "Before you start to scrape any website you should go through the terms of service and policy documents of the website. Almost all websites post conditions to use their data. Check the terms of [https://github.com/](https://github.com/) (see the tiny \"terms\" link at the bottom of the page) to see whether the site permits you to scrape their data or not. Are you sure you are allowed to scrape?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your solution:**\n",
    "\n",
    "Scraping is allowed for researchers as long as published works are open access and the information is not used for spamming purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 Load the Data\n",
    "\n",
    "To avoid any problems with GitHub blocking us from downloading the data many times, we have downloaded and saved a snapshot of the html files for you in the [data](data) folder. Note that the data folder is not completely consistent with what you see on the web â€“ we've made a few patches to the data that makes your task here easier and this data represents a snapshot in time. You will be treating the data folder as your website to be scraped. The path to data folder is stored in `DATA_PATH` variable.\n",
    "\n",
    "In the data folder you will find first 10 pages of highly starred repositories saved as `searchPage1.html`,`searchPage2.html`,`searchPage3.html` ... `searchPage10.html`\n",
    "\n",
    "Check out page 10 if you want to see what happens if you scrape too quickly ðŸ˜‰. \n",
    "\n",
    "Now read these html files in python and create a soup object. This is a two step process:\n",
    " * Read the text in the html files\n",
    " * Create the soup from the files that you've read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read html files and create soup files\n",
    "html_pages = []\n",
    "for files in os.listdir(DATA_PATH):\n",
    "    if files.endswith(\".html\"):\n",
    "        full_path = os.path.join(DATA_PATH, files)\n",
    "        with open(full_path, 'r') as f:\n",
    "            html_pages.append(f.read())\n",
    "\n",
    "SearchPage_soup = []\n",
    "for page in html_pages:\n",
    "    SearchPage_soup.append(BeautifulSoup(page, 'html.parser'))\n",
    "\n",
    "len(SearchPage_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data\n",
    "\n",
    "Extract the following data for each repository, and create a Pandas Dataframe with a row for each repository and a column for each of these datums. \n",
    "\n",
    "+ The name of the repository\n",
    "+ The primary language (there are multiple or none, if multiple, use the first one, if none, use \"none\")\n",
    "+ The number of watches\n",
    "+ The number of stars\n",
    "+ The number of forks\n",
    "+ The number of issues\n",
    "+ Number of commits\n",
    "+ Number of contributors\n",
    "+ Number of pull requests, and\n",
    "+ Number of top level folders in the file list.\n",
    "\n",
    "Here's an example for one repository, `jackfrued/Python-100-Days,` in our dataset: \n",
    "```python\n",
    "{'name': 'Python-100-Days',\n",
    "'language': 'Jupyter Notebook',\n",
    "'watches': '4822',\n",
    "'stars': '78068',\n",
    "'forks': '30979',\n",
    "'issues': 224,\n",
    "'commits': 296,\n",
    "'contributors': 12,\n",
    "'pull_requests':85,\n",
    "'folders': 14\n",
    "}\n",
    "```\n",
    "\n",
    "### Task 1.3 Extract repository URLs\n",
    "\n",
    "If you look at the results of the 100 most-starred repositories [(this list)](https://github.com/search?o=desc&q=stars%3A%3E1&s=stars&type=Repositories), you will notice that all the information we want to extract for each repository is not in that list. This information is in the repositoryâ€™s individual web page, for example [996icu](https://github.com/996icu/996.ICU). \n",
    "\n",
    "Therefore, you will first have to extract links of each repository from the soup you scraped earlier. When you extract the link for the repository, it will be a path to the stored HTML page for the repository. You will use this path to read the file and extract the above information.\n",
    "\n",
    "Refer to the scraping lecture for details on how to do this. We recommend you use the web inspector to identify the relevant structures.\n",
    "\n",
    "Example of a link that you need to extract - 996icu/996.ICU.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "['netdata/netdata', 'tonsky/FiraCode', 'denoland/deno', 'h5bp/html5-boilerplate', 'ElemeFE/element', 'adam-p/markdown-here', 'h5bp/Front-end-Developer-Interview-Questions', 'resume/resume.github.com', 'josephmisiti/awesome-machine-learning', 'lodash/lodash', 'angular/angular.js', 'puppeteer/puppeteer', 'mrdoob/three.js', 'microsoft/TypeScript', 'angular/angular', 'microsoft/terminal', 'laravel/laravel', 'moby/moby', 'ant-design/ant-design', 'iluwatar/java-design-patterns', 'ossu/computer-science', '30-seconds/30-seconds-of-code', 'mui-org/material-ui', 'jquery/jquery', 'webpack/webpack', 'reduxjs/redux', 'nvbn/thefuck', 'vuejs/awesome-vue', 'avelino/awesome-go', 'atom/atom', 'apple/swift', 'hakimel/reveal.js', 'MisterBooo/LeetCodeAnimation', 'PanJiaChen/vue-element-admin', 'pallets/flask', 'socketio/socket.io', 'expressjs/express', 'Semantic-Org/Semantic-UI', 'shadowsocks/shadowsocks-windows', 'chartjs/Chart.js', 'jwasham/coding-interview-university', 'kamranahmedse/developer-roadmap', 'github/gitignore', 'airbnb/javascript', 'microsoft/vscode', 'CyC2018/CS-Notes', 'd3/d3', 'flutter/flutter', 'torvalds/linux', 'facebook/react-native', 'nodejs/node', 'TheAlgorithms/Python', 'daneden/animate.css', 'kubernetes/kubernetes', 'justjavac/free-programming-books-zh_CN', 'FortAwesome/Font-Awesome', 'trekhleb/javascript-algorithms', 'tensorflow/models', 'ytdl-org/youtube-dl', 'danistefanovic/build-your-own-x', 'freeCodeCamp/freeCodeCamp', '996icu/996.ICU', 'vuejs/vue', 'facebook/react', 'tensorflow/tensorflow', 'twbs/bootstrap', 'EbookFoundation/free-programming-books', 'sindresorhus/awesome', 'getify/You-Dont-Know-JS', 'ohmyzsh/ohmyzsh', 'donnemartin/system-design-primer', 'electron/electron', 'vinta/awesome-python', 'jackfrued/Python-100-Days', 'facebook/create-react-app', 'public-apis/public-apis', 'axios/axios', 'golang/go', 'Snailclimb/JavaGuide', 'jlevy/the-art-of-command-line', 'django/django', 'elastic/elasticsearch', 'keras-team/keras', 'jakubroztocil/httpie', 'storybookjs/storybook', 'typicode/json-server', 'chrislgarry/Apollo-11', 'spring-projects/spring-boot', 'rails/rails', 'zeit/next.js']\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract all 'div' elements with class \"mt-n1\" (these classes contain individual repositories) from each item in SearchPage_soup.\n",
    "repositories = []\n",
    "\n",
    "for i in range(0, len(SearchPage_soup)):\n",
    "    mtn1 = SearchPage_soup[i].find_all('div', class_=\"mt-n1\")\n",
    "    for item in mtn1:\n",
    "        repo_links = item.find('a', class_=\"v-align-middle\")\n",
    "        repositories.extend(repo_links.text.split())\n",
    "\n",
    "print(len(repositories))\n",
    "print(repositories)\n",
    "\n",
    "repositories = [repo_path + '.html' for repo_path in repositories]\n",
    "\n",
    "htmls = []\n",
    "\n",
    "for repo_path in repositories:\n",
    "    # Construct the full path to the .html file\n",
    "    full_file_path = os.path.join(DATA_PATH, repo_path)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(full_file_path):\n",
    "        # Open and read the file\n",
    "        with open(full_file_path, 'r') as file:\n",
    "            html_content = file.read()\n",
    "            htmls.append(html_content)\n",
    "    else:\n",
    "        print(\"File not found:\", full_file_path)\n",
    "\n",
    "print(len(htmls))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "soups = []\n",
    "for page in htmls:\n",
    "    soups.append(BeautifulSoup(page, 'html.parser'))\n",
    "\n",
    "print(len(soups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "htmls = []\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".html\") and not any(file == f\"searchPage{i}.html\" for i in range(1, 11)):\n",
    "            full_path = os.path.join(root, file)\n",
    "            with open(full_path, 'r') as f:\n",
    "                htmls.append(f.read())\n",
    "\n",
    "soups = []\n",
    "for page in htmls:\n",
    "    soups.append(BeautifulSoup(page, 'html.parser'))\n",
    "\n",
    "print(len(soups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository Names\n",
    "repo_names = []\n",
    "\n",
    "for soup in soups:\n",
    "    element = soup.find(\"a\", attrs={\"data-pjax\": \"#js-repo-pjax-container\"})\n",
    "    repo_names.append(element.text)\n",
    "\n",
    "# Languages\n",
    "lang = []\n",
    "\n",
    "for soup in soups:\n",
    "    element = soup.find(\"span\", class_=\"language-color\")\n",
    "    if element:\n",
    "        lang.append(element.text)\n",
    "    else:\n",
    "        lang.append(\"None\")\n",
    "\n",
    "# Number of watchers\n",
    "watchers = []\n",
    "\n",
    "for soup in soups:\n",
    "    element = soup.find(\"a\", class_=\"social-count\", href=lambda x: x and \"/watchers\" in x)\n",
    "    watchers.append(element.text.strip())\n",
    "\n",
    "# Number of stars\n",
    "stars = []\n",
    "\n",
    "for soup in soups:\n",
    "    element = soup.find('a', class_=\"social-count js-social-count\", href=lambda x: x and \"/stargazers\" in x)\n",
    "    stars.append(element.text.strip())\n",
    "\n",
    "# Number of forks\n",
    "forks = []\n",
    "\n",
    "for soup in soups:\n",
    "    soup.find('a', class_=\"social-count\", href=lambda x: x and \"/members\" in x)\n",
    "    forks.append(element.text.strip())\n",
    "\n",
    "# Number of Issues\n",
    "issues = []\n",
    "\n",
    "for soup in soups:\n",
    "    issue_link = soup.find('a', href=lambda x: x and '/issues' in x)\n",
    "    if issue_link:\n",
    "        issue_count = issue_link.find('span', class_='Counter')\n",
    "        if issue_count:\n",
    "            issues.append(issue_count.text.strip())\n",
    "        else:\n",
    "            issues.append(None)\n",
    "    else:\n",
    "        issues.append(None)\n",
    "\n",
    "# Number of commits\n",
    "commits = []\n",
    "\n",
    "for soup in soups:\n",
    "    commit_link = soup.find('a', href=lambda x: x and '/commits/master' in x)\n",
    "    if commit_link:\n",
    "        commit_count = commit_link.find('span', class_='num text-emphasized')\n",
    "        if commit_count:\n",
    "            commits.append(commit_count.text.strip())\n",
    "        else:\n",
    "            commits.append(None)\n",
    "    else:\n",
    "        commits.append(None)   \n",
    "\n",
    "#  Number of contributors\n",
    "contributors = []\n",
    "\n",
    "for soup in soups:\n",
    "    contributors_link = soup.find('a', href=lambda x: x and '/contributors' in x)\n",
    "    contributors_count = contributors_link.find('span', class_='num text-emphasized')\n",
    "    contributors.append(contributors_count.text.strip())\n",
    "\n",
    "\n",
    "# Number of pulls\n",
    "pulls = []\n",
    "\n",
    "for soup in soups:\n",
    "    pulls_link = soup.find('a', href=lambda x: x and '/pulls' in x)\n",
    "    pulls_count = pulls_link.find('span', class_='Counter')\n",
    "    pulls.append(pulls_count.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"Name\": repo_names, \"Language\": lang, \"Watchers\": watchers, \"Stars\": stars, \"Forks\": forks, \"Issues\": issues, \"Commits\": commits, \"Contributors\": contributors, \"Pull_Requests\": pulls}\n",
    "project_info = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4 Extracting required information\n",
    "\n",
    "Once you have extracted links for each repository, you can start parsing those HTML pages using BeautifulSoup and extract all the required information.\n",
    "\n",
    "**Note**: There are few repositories which do not contain 'issues' field (such as 996icu/996.ICU.html). Therefore, write your code such that it handles this condition as well.\n",
    "\n",
    "**Save the dataframe you created to a new file project_info.csv and include this in your submission.** This separate file will also be graded and is required to earn points.\n",
    "\n",
    "You also need to make sure that you reformat all numerical columns to be integer data. You can do that either as you parse, or when you have a dataframe with strings.\n",
    "\n",
    "Note that there is one repository flagged as having infinite contributers (the Linux kernel). We'll assume that it in fact has 15600 contributors (an estimate based on a Google search at the time of download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_convert(value):\n",
    "    value_str = str(value)\n",
    "    if 'k' in value_str:\n",
    "        # Remove 'k' and convert to float, then multiply by 1000\n",
    "        return int(float(value.replace('k', '')) * 1000)\n",
    "    else:\n",
    "        return int(value)\n",
    "\n",
    "# Apply the conversion function to the 'Counts' column\n",
    "project_info['Watchers'] = project_info['Watchers'].apply(int_convert)\n",
    "project_info['Stars'] = project_info['Stars'].apply(int_convert)\n",
    "project_info['Forks'] = project_info['Forks'].apply(int_convert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Language</th>\n",
       "      <th>Watchers</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Forks</th>\n",
       "      <th>Issues</th>\n",
       "      <th>Commits</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Pull_Requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netdata</td>\n",
       "      <td>C</td>\n",
       "      <td>1400</td>\n",
       "      <td>44800</td>\n",
       "      <td>45000</td>\n",
       "      <td>680</td>\n",
       "      <td>9,816</td>\n",
       "      <td>323</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FiraCode</td>\n",
       "      <td>Clojure</td>\n",
       "      <td>720</td>\n",
       "      <td>44400</td>\n",
       "      <td>45000</td>\n",
       "      <td>222</td>\n",
       "      <td>364</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deno</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1500</td>\n",
       "      <td>44400</td>\n",
       "      <td>45000</td>\n",
       "      <td>320</td>\n",
       "      <td>2,786</td>\n",
       "      <td>220</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>html5-boilerplate</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>2600</td>\n",
       "      <td>44000</td>\n",
       "      <td>45000</td>\n",
       "      <td>2</td>\n",
       "      <td>1,778</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>element</td>\n",
       "      <td>Vue</td>\n",
       "      <td>1400</td>\n",
       "      <td>43800</td>\n",
       "      <td>45000</td>\n",
       "      <td>1,235</td>\n",
       "      <td>None</td>\n",
       "      <td>501</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>json-server</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>973</td>\n",
       "      <td>45500</td>\n",
       "      <td>45000</td>\n",
       "      <td>448</td>\n",
       "      <td>789</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Apollo-11</td>\n",
       "      <td>Assembly</td>\n",
       "      <td>1300</td>\n",
       "      <td>45400</td>\n",
       "      <td>45000</td>\n",
       "      <td>14</td>\n",
       "      <td>354</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>spring-boot</td>\n",
       "      <td>Java</td>\n",
       "      <td>3400</td>\n",
       "      <td>45400</td>\n",
       "      <td>45000</td>\n",
       "      <td>423</td>\n",
       "      <td>25,192</td>\n",
       "      <td>651</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>rails</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>2600</td>\n",
       "      <td>45000</td>\n",
       "      <td>45000</td>\n",
       "      <td>404</td>\n",
       "      <td>75,943</td>\n",
       "      <td>3,973</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>next.js</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>846</td>\n",
       "      <td>45000</td>\n",
       "      <td>45000</td>\n",
       "      <td>272</td>\n",
       "      <td>None</td>\n",
       "      <td>917</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name    Language  Watchers  Stars  Forks Issues Commits  \\\n",
       "0             netdata           C      1400  44800  45000    680   9,816   \n",
       "1            FiraCode     Clojure       720  44400  45000    222     364   \n",
       "2                deno  TypeScript      1500  44400  45000    320   2,786   \n",
       "3   html5-boilerplate  JavaScript      2600  44000  45000      2   1,778   \n",
       "4             element         Vue      1400  43800  45000  1,235    None   \n",
       "..                ...         ...       ...    ...    ...    ...     ...   \n",
       "85        json-server  JavaScript       973  45500  45000    448     789   \n",
       "86          Apollo-11    Assembly      1300  45400  45000     14     354   \n",
       "87        spring-boot        Java      3400  45400  45000    423  25,192   \n",
       "88              rails        Ruby      2600  45000  45000    404  75,943   \n",
       "89            next.js  JavaScript       846  45000  45000    272    None   \n",
       "\n",
       "   Contributors Pull_Requests  \n",
       "0           323            37  \n",
       "1            70             2  \n",
       "2           220            32  \n",
       "3           231             1  \n",
       "4           501           294  \n",
       "..          ...           ...  \n",
       "85           60            60  \n",
       "86          103             4  \n",
       "87          651            27  \n",
       "88        3,973           239  \n",
       "89          917            30  \n",
       "\n",
       "[90 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(project_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_info.to_csv('project_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyzing the repository data\n",
    "\n",
    "In this part, you will analyze the data collected in Part 1 using regression tools. The goal is to identify properties that make a repository popular. \n",
    "\n",
    "First, load the `project_info.csv` file in again. **We need you to do this so that we can run your code below without having to run your scraping code, which can be slow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Language</th>\n",
       "      <th>Watchers</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Forks</th>\n",
       "      <th>Issues</th>\n",
       "      <th>Commits</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Pull_Requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netdata</td>\n",
       "      <td>C</td>\n",
       "      <td>1400</td>\n",
       "      <td>44800</td>\n",
       "      <td>45000</td>\n",
       "      <td>680</td>\n",
       "      <td>9,816</td>\n",
       "      <td>323</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FiraCode</td>\n",
       "      <td>Clojure</td>\n",
       "      <td>720</td>\n",
       "      <td>44400</td>\n",
       "      <td>45000</td>\n",
       "      <td>222</td>\n",
       "      <td>364</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deno</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1500</td>\n",
       "      <td>44400</td>\n",
       "      <td>45000</td>\n",
       "      <td>320</td>\n",
       "      <td>2,786</td>\n",
       "      <td>220</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>html5-boilerplate</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>2600</td>\n",
       "      <td>44000</td>\n",
       "      <td>45000</td>\n",
       "      <td>2</td>\n",
       "      <td>1,778</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>element</td>\n",
       "      <td>Vue</td>\n",
       "      <td>1400</td>\n",
       "      <td>43800</td>\n",
       "      <td>45000</td>\n",
       "      <td>1,235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>501</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name    Language  Watchers  Stars  Forks Issues Commits  \\\n",
       "0            netdata           C      1400  44800  45000    680   9,816   \n",
       "1           FiraCode     Clojure       720  44400  45000    222     364   \n",
       "2               deno  TypeScript      1500  44400  45000    320   2,786   \n",
       "3  html5-boilerplate  JavaScript      2600  44000  45000      2   1,778   \n",
       "4            element         Vue      1400  43800  45000  1,235     NaN   \n",
       "\n",
       "  Contributors  Pull_Requests  \n",
       "0          323             37  \n",
       "1           70              2  \n",
       "2          220             32  \n",
       "3          231              1  \n",
       "4          501            294  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_info = pd.read_csv('project_info.csv')\n",
    "project_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 Describe the data\n",
    "\n",
    "+ Get an overview of the data using the describe function.\n",
    "+ Compute the correlation matrix, visualize it with a heat map.\n",
    "+ Visualize the correlations by making a scatterplot matrix.\n",
    "+ Interprete what you see.\n",
    "\n",
    "You can re-use code from your previous homework here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watchers</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Forks</th>\n",
       "      <th>Pull_Requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2901.636364</td>\n",
       "      <td>68723.376623</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>95.948052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1824.785264</td>\n",
       "      <td>37002.225737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.055036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>336.000000</td>\n",
       "      <td>43500.000000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1600.000000</td>\n",
       "      <td>47300.000000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2500.000000</td>\n",
       "      <td>57700.000000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3400.000000</td>\n",
       "      <td>76000.000000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8600.000000</td>\n",
       "      <td>309000.000000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Watchers          Stars    Forks  Pull_Requests\n",
       "count    77.000000      77.000000     77.0      77.000000\n",
       "mean   2901.636364   68723.376623  45000.0      95.948052\n",
       "std    1824.785264   37002.225737      0.0     152.055036\n",
       "min     336.000000   43500.000000  45000.0       0.000000\n",
       "25%    1600.000000   47300.000000  45000.0      13.000000\n",
       "50%    2500.000000   57700.000000  45000.0      35.000000\n",
       "75%    3400.000000   76000.000000  45000.0     108.000000\n",
       "max    8600.000000  309000.000000  45000.0     900.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_info_cleaned = project_info.dropna()\n",
    "project_info_cleaned.loc[:, 'Issues'] = project_info_cleaned['Issues'].str.replace('+', '').str.replace(',', '').astype(int)\n",
    "project_info_cleaned.loc[:,'Commits'] = project_info_cleaned['Commits'].str.replace(',', '').astype(int)\n",
    "project_info_cleaned.loc[:, 'Contributors'] = project_info_cleaned['Contributors'].str.replace(',', '').astype(int)\n",
    "project_info_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1,235'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Remove non-numeric columns and compute correlation matrix\u001b[39;00m\n\u001b[1;32m      4\u001b[0m project_info \u001b[38;5;241m=\u001b[39m project_info\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mproject_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot correlation matrix\u001b[39;00m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10704\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10702\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  10703\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 10704\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  10706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  10707\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:1889\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1888\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1889\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1891\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1713\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1715\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1,235'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Remove non-numeric columns and compute correlation matrix\n",
    "project_info = project_info.drop(columns=['Name', 'Language'])\n",
    "correlation_matrix = project_info.corr()\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Linear regression\n",
    "\n",
    "1. Use linear regression to try to predict the number of Stars based on Forks, Pull Requests, and Number of Folders. Explain why this is not a very good model by discussing the R-squared , F-statistic p-value, and coefficient  p-values. \n",
    "+ Develop another model which is better. Explain why it is better and interpret your results. Hint: try using other variables such as Watches and/or Contributors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your interpretation:** TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
