{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dac6427e-b8df-46f9-bfd3-b24427a73993"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Data Science \n",
    "# Lecture 7: Statistical inference and hypothesis testing\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this lecture, we'll cover \n",
    "* Statistical inference\n",
    "* Central limit theorem\n",
    "* Hypothesis testing and the z-test\n",
    "* Confidence intervals\n",
    "* A/B testing\n",
    "\n",
    "Mandatory reading:\n",
    "+ [WIRED article on A/B testing](http://www.wired.com/2012/04/ff-abtesting/)\n",
    "\n",
    "Mandatory listening:\n",
    "+ [Planet Money Episode 677: The experiment experiment](https://www.npr.org/sections/money/2018/03/07/591213302/episode-677-the-experiment-experiment)\n",
    "+ [Planet Money Episode 669: A or B](https://www.npr.org/sections/money/2015/12/11/459412925/episode-669-a-or-b) \n",
    "\n",
    "Further reading: \n",
    "+ Jay L. Devore, Probability and Statistics for Engineering and the Sciences, 9th ed. Cengage Learning (2016) Ch. 8 and 9.\n",
    "+ R. Nuzzo, Scientific method: Statistical errors, Nature (2014) [link](https://doi.org/10.1038/506150a)\n",
    "+ J. Cohen, The Earth is Round (p<0.05), American Psychologist (1994) [link](https://doi.org/10.1037/0003-066x.49.12.997)\n",
    "\n",
    "\n",
    "For a more complete treatment, take Math 3070 (Applied Statistics I).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports and setup\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy as sc\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import probplot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Recap of Lecture 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descriptive vs. Inferential Statistics \n",
    "\n",
    "*Descriptive statistics* quantitatively describes or summarizes features of a dataset. \n",
    "\n",
    "*Inferential statistics* attempts to learn about the population from which the data was sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete random variables\n",
    "\n",
    "*Discrete random variables* take discrete values with preassigned probabilities described by a probability mass function (PMF). If $X$ is the random variable and $f(k)$ is the PMF, we say \"the probability that $X$ takes value $k$ is given by $f(k)$\" and write\n",
    "$$\n",
    "\\textrm{Prob}(X=k) = f(k).\n",
    "$$\n",
    "\n",
    "### Bernoulli distribution\n",
    "A Bernoulli random variable can take the values $k=0$ or $1$ and has PMF\n",
    "$$\n",
    "f(k) = \\begin{cases} p & k=1 \\\\ 1-p & k = 0 \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Some facts about Bernoulli variables: \n",
    "* mean is $p$\n",
    "* variance is $p(1-p)$\n",
    "\n",
    "**Example:** The Bernoulli distribution with $p=0.5$ describes a 'fair' coin toss where 1 and 0  represent \"heads\" and \"tails\", respectively. If the coin is unfair, then we would have that $p\\neq 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Binomial distribution\n",
    "\n",
    "A binomial r.v. takes values $k=0,1,\\ldots,n$, with a probability given by the PMF \n",
    "$$\n",
    "f(k) = \\binom{n}{k} p^k (1-p)^{n-k}.\n",
    "$$\n",
    "Here, $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ in the binomial coefficient that describes how many ways there are to choose a subset of $k$ elements, disregarding their order, from a set of $n$ elements.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n =10\n",
    "p = 0.5\n",
    "f = lambda k: binom.pmf(k, n=n,p=p)\n",
    "\n",
    "x = range(n+1);\n",
    "plt.plot(x, f(x),'*-')\n",
    "plt.title(\"The PMF for a binomial random variable\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"f(k)\")\n",
    "plt.xlim([0,n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Some facts about the binomial distribution:\n",
    "- A binomial random variable is just the sum of $n$ Bernoulli random variables. You can think of it as summarizing the resutls of $n$ coin flips by just keeping track of the total number of heads.\n",
    "- The mean is  $np$\n",
    "- The variance is  $np(1âˆ’p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Poisson distribution\n",
    "You also saw the Poisson random variable in the homework, which is another example of a discrete random variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous random variables\n",
    "\n",
    "A *continuous random variable* can take any real value, but some numbers are more likely than others. The probability is given by the *probability density function (PDF)*, which is analogous to the PMF for discrete random variables. If f(x) is the PDF for the random variable $X$, then the probability that $X$ takes the value in the interval $[a,b]$ is given by \n",
    "$$\n",
    "\\textrm{Prob}(X\\in[a,b]) = \n",
    "\\int_a^b f(x) dx.\n",
    "$$\n",
    "This is just the area under the curve for this interval.\n",
    "\n",
    "### Example: Normal (Gaussian) distribution \n",
    "\n",
    "The *probability density function (PDF)* for a normal (Gaussian) random variable is\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
    "e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} }.\n",
    "$$\n",
    "This is sometimes referred to as the 'bell curve'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation \n",
    "x = np.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "pdf = norm.pdf(x,loc=mu, scale=sigma)\n",
    "plt.title(\"The probability density function for a normal random variable\")\n",
    "plt.plot(x, pdf, linewidth=2, color='k')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some facts about the normal distribution:\n",
    "- The mean is $\\mu$\n",
    "- The variance is  $\\sigma^2$\n",
    "\n",
    "To compute the integral \n",
    "$$\n",
    "\\textrm{Prob}(X\\in[a,b]) = \n",
    "\\int_a^b f(x) dx,\n",
    "$$\n",
    "it is useful to define the *cumulative distribution function* (CDF)\n",
    "$$\n",
    "F(x) = \\textrm{Prob}(X\\leq x) = \\int_{-\\infty}^x f(y) dy.\n",
    "$$\n",
    "Then we can write \n",
    "$$\n",
    "\\int_a^b f(x) dx =\n",
    "\\int_{-\\infty}^b f(x) dx  - \\int_{-\\infty}^a f(x) dx =\n",
    "F(b) - F(a).\n",
    "$$\n",
    "This is convenient because we no longer have to evaluate an integral! However, there isn't a nice way to write $F(x)$ for the normal distribution in terms of elementary functions. So we just think about $F(x)$ as a known function that we can easily compute using python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation \n",
    "x = np.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "cdf = norm.cdf(x,loc=mu, scale=sigma)\n",
    "plt.title(\"The cumulative density function for a normal random variable\")\n",
    "plt.plot(x, cdf, linewidth=2, color='k')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"F(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercise \n",
    "Interpret the following in terms of normal random variables:\n",
    "- $\\int_{-\\infty}^1 f(x) dx = F(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(1, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- $\\int_{-1}^1 f(x) dx = F(1) - F(-1)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(1, loc=mu, scale=sigma) - norm.cdf(-1, loc=mu, scale=sigma) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "+ $\\int_{-\\infty}^\\infty f(x) dx = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(sc.inf, loc=mu, scale=sigma)-norm.cdf(-sc.inf, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "+ $\\int_1^1 f(x) dx = F(1) - F(1) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf(1, loc=mu, scale=sigma)-norm.cdf(1, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "**Remark:** There are many other continuous random variables, but in this class we'll mostly only consider the normal random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: One sample statistical inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.1. Checking if a random variable is a normal random variable \n",
    "\n",
    "Given sample data, $x_1, x_2, x_3 \\ldots$, how do you know if the data came from a normal distribution? \n",
    "\n",
    "+ There is a visual check called the ***\"normal probability plot\"*** (from scipy.stats import probplot). \n",
    "\n",
    "In a [normal probability plot](https://en.wikipedia.org/wiki/Normal_probability_plot), the sorted data are plotted vs. values selected to make the points look close to a straight line if the data are approximately normally distributed. Deviations from a straight line suggest departures from normality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_size = 200\n",
    "plt.rcParams['figure.figsize'] = (5, 3)\n",
    "\n",
    "# Normal distribution\n",
    "x = norm.rvs(loc=0, scale=1, size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot: Normal distribution\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()\n",
    "\n",
    "# Heavy-tailed distribution, t distribution\n",
    "x = t.rvs(df=3,size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot: t distribution\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\") \n",
    "plt.show()\n",
    "\n",
    "# Heavy-tailed distribution, Laplace distribution\n",
    "from scipy.stats import laplace\n",
    "x = laplace.rvs(size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot Laplace distribution\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()\n",
    "\n",
    "# Skewed right distribution, Gamma distribution\n",
    "from scipy.stats import gamma\n",
    "x = gamma.rvs(a=2,size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot: Gamma distribution\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2. Hypothesis testing\n",
    "\n",
    "Suppose we have a coin and we want to determine whether or not it is 'fair'. We could flip it many, many times and count how many heads we obtain. If the fraction of heads is approximately $0.5$, we might argue that the coin is fair. \n",
    "\n",
    "This is an example of statistical inference. We are trying to determine something about the coin from samples of coin flips. \n",
    "\n",
    "Let's say we flip a coin $n=1000$ times. If the coin is fair, the outcome is described by the Binomial distribution with $p=0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f = lambda k: binom.pmf(k, n=1000,p=0.5)\n",
    "\n",
    "x = range(1001);\n",
    "plt.plot(x, f(x),'*-')\n",
    "plt.plot(545,f(545),'o')\n",
    "plt.title(\"The probability mass function for a Binomial random variable\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"f(k)\")\n",
    "plt.xlim([0,1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Suppose that in our experiment, we saw $545$ heads. The probability of this occurring is \n",
    "f(k = 545):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "binom.pmf(545, n=1000,p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In hypothesis testing, the more important question is: ***what is the probability of seeing a value as extreme or more extreme than the value that we observed?*** \n",
    "\n",
    "We might say that any result $\\geq 545$ is 'as or more extreme'.\n",
    "\n",
    "So the probability of seeing as extreme of an outcome is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = sum(binom.pmf(np.arange(545,1001),n=1000,p=0.5))\n",
    "print(s)\n",
    "print(1-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Actually, seeing any result $\\leq 455$ would be 'as or more extreme' too. Why?\n",
    "\n",
    "So the probability of seeing as extreme of an outcome is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = sum(binom.pmf(np.arange(0,456),n=1000,p=0.5)) # why 456? \n",
    "s2 = sum(binom.pmf(np.arange(545,1001),n=1000,p=0.5))\n",
    "print(s1)\n",
    "print(s2)\n",
    "s = s1 + s2\n",
    "\n",
    "print(s)\n",
    "print(1-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So **if the coin were fair,** the probability of seeing so many heads or so many tails is just 0.49%. So if the coin were fair, it is **very unlikely** that we would see this result! In fact, it is so unlikely that we should probably just conclude that the coin is unfair. This is the idea behind **hypothesis testing**. \n",
    "\n",
    "---\n",
    "\n",
    "In *hypothesis testing*, we make a ***null hypothesis***, written $H_0$. In this case, the null hypothesis is\n",
    "\n",
    "$$\n",
    "H_0: \\text{the coin is fair, i.e., $p=0.5$}.\n",
    "$$\n",
    "\n",
    "The ***alternative hypothesis***, $H_a$, is typically the hypothesis that the researcher wants to validate. In this case: \n",
    "\n",
    "$$\n",
    "H_a: \\text{the coin is unfair, i.e., $p\\neq 0.5$}.\n",
    "$$\n",
    "\n",
    "We also choose a *significance level* for the test, $\\alpha$, traditionally $1\\%$ or $5\\%$. \n",
    "In this case, let's choose a significance level of $\\alpha = 1\\%$. \n",
    "\n",
    "We then collect a *random sample*. In this case, we flip the coin 1000 times and count the number of heads (in this case 545). More generally, we collect a random sample of data from the population of interest. \n",
    "\n",
    "Finally, assuming the null hypothesis is true, we compute *how likely it is to see a number that is at least as far from the expected value as the number obtained from the random sample*. In our case, this is $0.49\\%$. This is called the **p-value**. Since $p=0.49\\%$ is smaller than the chosen significance level, $\\alpha = 1\\%$, we **reject the null hypothesis** and declare the coin to be unfair.  \n",
    "\n",
    "Some comments about the p-value:\n",
    "+ A p-value is a probability calculated assuming that $H_0$ is true.  \n",
    "\n",
    "+ The smaller the p-value, the stronger the evidence against $H_0$.\n",
    "\n",
    "+ **Warning:** A p-value is not the probability that the null hypothesis is true or false. It is the probability of observing an event as extreme as the one we did, assuming the null hypothesis to be true. In this example, it is the probability that, assuming the coin is fair, one would observe a count which is 45 or more away from the mean (i.e. $\\textrm{Prob}(|X - \\mu| \\geq 45) =\\textrm{Prob}(X - \\mu \\geq 45)+ \\textrm{Prob}(X - \\mu \\leq -45)$).\n",
    "\n",
    "What we did here was very distribution specific (i.e. to do the hypothesis test we needed access to the binomial pmf/cdf). We want a more general procedure, which can be developed utilizing the *Central Limit Thoerem*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Limit Theorem \n",
    "\n",
    "One of the reasons that the normal distribution is **so important** is the following theorem. \n",
    "\n",
    "**Central Limit Theorem.** Let $\\{X_1,\\ldots, X_n\\}$ be a sample of $n$ random variables chosen identically and independently from a distribution with mean $\\mu$ and finite variance $\\sigma^2$. If $n$ is 'large', then \n",
    "- the sum of the variables $\\sum_{i=1}^n X_i$ is also a random variable and is approximately **normally** distributed with mean $n\\mu$ and variance $n\\sigma^2$ and\n",
    "- the mean of the variables $\\frac{1}{n}\\sum_{i=1}^n X_i$ is also a random variable and is approximately **normally** distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "\n",
    "How can we use the central limit theorem (CLT)? \n",
    "\n",
    "Recall that a binomial random variable is the sum of $n$ Bernoulli random variables. So the CLT tells us that if $n$ is large, binomial random variables will be distributed approximately normally. That is, ***if we flip a coin many times, the number of heads that we're likely to see is described by a normal distribution.*** This provides a different (easier) way to answer the question: How unlikely is it to flip a fair coin 1000 times and see 545 heads? \n",
    "\n",
    "Suppose we flip a fair ($p=0.5$) coin 1000 times. \n",
    "\n",
    "*Question:* How many heads do we expect to see? \n",
    "\n",
    "The CLT says that the number of heads (= sum of Bernoulli r.v. = binomial r.v.) is approximately normally distributed with mean \n",
    "$$ \n",
    "n\\mu = np = 1000*0.5 = 500 \n",
    "$$\n",
    "and variance \n",
    "$$ \n",
    "n \\sigma^2 = np(1-p) = 1000*0.5*0.5 = 250. \n",
    "$$\n",
    "\n",
    "Let's do an experiment to see how good the CLT is for Bernoulli random variables. We'll call flipping a fair coin n=1,000 times and counting the number of heads a \"simulation\". Recall that the outcome is precisely a binomial random variable with n=1,000 and p = 0.5. We'll do 10,000 simulations and then compare the histogram of the binomial random variables and the normal distribution predicted by the CLT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 0.5\n",
    "bin_vars = binom.rvs(n=n,p=p,size=10000)\n",
    "\n",
    "plt.hist(bin_vars, bins=20,density=True)\n",
    "\n",
    "mu = n*p \n",
    "sigma = np.sqrt(n*p*(1-p))\n",
    "x = np.arange(mu-4*sigma,mu+4*sigma,0.1);\n",
    "pdf = norm.pdf(x, loc=mu, scale=sigma)\n",
    "plt.plot(x, pdf, linewidth=2, color='k')\n",
    "plt.title(\"A comparison between the histogram of binomial random \\n variables and the normal distribution predicted by the CLT\")\n",
    "plt.show()\n",
    "\n",
    "# Check if the random variable is close to normal or not\n",
    "probplot(bin_vars, plot=plt)\n",
    "plt.title(\"Normal probability plot\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So what is the likelihood of flipping a fair coin 1000 times and seeing an event less extreme than 545 heads? \n",
    "\n",
    "The CLT tells us that this is approximately \n",
    "$$\n",
    "\\int_{455}^{545} f(x) dx = F(545) - F(455).\n",
    "$$\n",
    "\n",
    "This is something that we can easily evaluate using the cumulative distribution function (CDF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 0.5\n",
    "mu = n*p\n",
    "sigma = np.sqrt(n*p*(1-p))\n",
    "s2 = norm.cdf(545, loc=mu, scale=sigma) - norm.cdf(455, loc=mu, scale=sigma)\n",
    "print(s2) # Approximate probability of being less extreme \n",
    "print(1-s2) # Approximate probability of being more extreme  \n",
    "\n",
    "# a plot illustrating the integral \n",
    "x = np.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "plt.plot(x, norm.pdf(x, loc=mu, scale=sigma), linewidth=2, color='k')\n",
    "x2 = np.arange(455,545,0.001)\n",
    "plt.fill_between(x2, y1= norm.pdf(x2,loc=mu, scale=sigma), facecolor='red', alpha=0.5)\n",
    "plt.xlim([mu-4*sigma,mu+4*sigma])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So again, we see that $99.5\\%$ of the time, we would see an event less extreme than 545 heads.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: \"Freshman 15\": Fact or Fiction\n",
    "\n",
    "This example was taken from Devore, pp.314-315. \n",
    "\n",
    "\"A common belief among the lay public is that body weight increases after entry into college, and the phrase 'freshman 15' has been coined to describe the ***15 pounds that students presumably gain over their freshman year***.\"\n",
    "\n",
    "Let $\\mu$ denote the true average weight gain in the first year of college. We take the null hypothesis to be\n",
    "$$\n",
    "H_0: \\mu \\geq 15\n",
    "$$\n",
    "so that the alternative hypothesis is that the average weight gain in the first year of college is less than 15 lbs ($H_a:  \\mu < 15$). \n",
    "\n",
    "We set a significance level of, say, $\\alpha = 1\\%$. \n",
    "\n",
    "We suppose a random sample of $n$ students is selected, their weights (before and after the first year of college) are measured, and the sample mean $\\bar{x}$ and sample standard deviation $s$ are computed. An article in the journal Obesity (2006) cites that for a sample of $n=137$ students, the sample mean weight gain was $\\bar{x}=2.42$ lb and with a sample standard deviation of $s=5.72$ lb. \n",
    "\n",
    "Assuming $H_0$ to be true, how unlikely is it that we would observe such a small value ($\\bar{x}=2.42$)?  \n",
    "\n",
    "The CLT says that \n",
    "+ the mean of the variables $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i$ is a random variable and is approximately **normally** distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "\n",
    "\n",
    "We take a normal distribution with mean given by the null value ($\\mu = 15$) and variance given by $s^2/n = (5.72)^2/137=0.2388$ ($s$ computed from the sample). \n",
    "\n",
    "The $p$-value is then computed as the probability that $\\bar{X}< 2.42 = \\bar{x}$, \n",
    "$$\n",
    "P(\\bar{X}< 2.42) = \\int_{-\\infty}^{2.42} f(x) dx = F(2.42).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu = 15\n",
    "sigma = np.sqrt(5.72**2/137)\n",
    "print('p:', norm.cdf(2.42, loc=mu, scale=sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The p-value is practically zero, much less than the significance level! The data very strongly contradicts the null hypothesis. We reject the null hypothesis, $H_0$, and conclude that the 'freshman 15' is fiction! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Zinc in Batteries\n",
    "\n",
    "This example was taken from Devore, pp.317. \n",
    "\n",
    "A random sample of $n=51$ Panasonic AAA batteries gave a sample mean zinc mass of $\\bar{X}=2.06$ grams and a sample standard deviation of $s=0.141$ grams. \n",
    "\n",
    "**Question**: Does this data provide compelling evidence for concluding that the population mean zinc mass exceeds 2.0 grams, as reported by the company? \n",
    "\n",
    "Let $\\mu$ denote the true average zinc mass of such batteries. We take the null hypothesis to be\n",
    "$$\n",
    "H_0: \\mu \\leq 2.0\n",
    "$$\n",
    "and that the alternative hypothesis is\n",
    "$$\n",
    "H_a:  \\mu > 2.0.\n",
    "$$\n",
    "\n",
    "We set a significance level of, say, $\\alpha = 1\\%$. \n",
    "\n",
    "According to the CLT, the sample mean $\\bar{X}$ has approximately a normal distribution with mean $\\mu = 2.0$ (Assuming $H_0$, 2.0 is the most extreme case in $H_0$) and standard deviation $\\sigma/\\sqrt{n}\\approx s/\\sqrt{n}$. We could proceed as previously but it is more standard to normalize the variable.  \n",
    "\n",
    "To proceed, we conduct a **z-test**, which is the same as we did in the previous example, except now we use the normalized $Z$-statistic, \n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\sigma/\\sqrt{n}} \\approx \\frac{2.06 - 2.0}{0.141/\\sqrt{51}} = 3.04. \n",
    "$$\n",
    "\n",
    "If $H_0$ it true, the observed statistic is 3.04 standard deviations above the mean.\n",
    "\n",
    "***The $Z$-statistic is (approximately) distributed according to the \"standard\" normal distribution with mean $\\mu=0$ and standard deviation $\\sigma = 1$.***\n",
    "\n",
    "Assuming $H_0$ to be true, how unlikely is it that we would observe such a large value ($\\bar{x}=2.06$)?\n",
    "$$\n",
    "P-\\text{value} = P (\\bar{X} \\geq 2.06) = P (Z\\geq 3.04) = \\int_{3.04}^\\infty f(x) dx = 1 - F(3.04) = .0012.  \n",
    "$$\n",
    "Because the $P$-value $= .0012 \\leq .01 = \\alpha$, the null hypothesis should be rejected at the chosen significance level. We conclude that the average zinc mass in the batteries exceeds 2.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1 - norm.cdf(2.06, loc=2.0, scale = 0.141/np.sqrt(51)))\n",
    "\n",
    "z = (2.06 - 2.0) / (0.141/np.sqrt(51))\n",
    "print(1 - norm.cdf(z, loc=0, scale=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3. Summary of hypothesis testing and the z-test\n",
    "+ Identify the parameter of interest and describe it in the context of the problem. \n",
    "+ Determine the null and alternative hypotheses.\n",
    "+ Choose a significance level $\\alpha$. \n",
    "+ Find the formula for the computed value of the test statistic, *e.g.*, \n",
    "$Z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}$ (use the CLT). (Note as we saw with the coin tosses, if the data is binary and $H_A$ involves a proportion, applying the CLT to a sum of Bernoulli's gives $Z = \\frac{\\hat{p} - p}{\\sqrt{\\frac{p(1-p)}{n}}}$ where $\\hat{p}$ is the sample proportion.)\n",
    "+ Using the sampled data, compute the $P$-value, *e.g.*, $F(z)$\n",
    "+ Compare the significance level to the $P$-value to decide whether or not the null hypothesis should be rejected and state the conclusion in the problem context. Report the $P$-value! \n",
    "\n",
    "\n",
    "\n",
    "### One- and two- sided hypothesis testing:\n",
    "\n",
    "Depending on the null and alternative hypothesis, the $P$-value will be different integrals of the 'bell curve'. This is called [one- and two- sided hypothesis testing](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests).\n",
    "\n",
    "<img src=\"determinePvals.png\" width=\"600\">\n",
    "$\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad$ \n",
    "source: Devore, pp.329\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.4. What to do for smaller sample sizes? Student's t-test\n",
    "\n",
    "When $n$ is small, the Central Limit Theorem can no longer be used. In this case, if the samples are drawn from an approximately normal distribution, then the correct distribution to use is called the [Student's t distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) with $\\nu = n-1$ degrees of freedom. The probability density function (pdf) for the student's t distribution is not pretty (Google it!) but it is built into scipy, so we can compare the student's t-test to the normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# there is some trouble with this package for some python versions\n",
    "# if it doesn't work, don't worry about it\n",
    "from ipywidgets import interact \n",
    "\n",
    "samp_mean = 0\n",
    "samp_std_dev = 1\n",
    "\n",
    "x = np.linspace(samp_mean-4*samp_std_dev,samp_mean+4*samp_std_dev,1000);\n",
    "def compare_distributions(sample_size):\n",
    "    pdf1 = norm.pdf(x, loc=samp_mean, scale=samp_std_dev/np.sqrt(sample_size))\n",
    "    pdf2 = t.pdf(x,df=sample_size-1,loc=samp_mean, scale=samp_std_dev/np.sqrt(sample_size))\n",
    "    plt.plot(x, pdf1, linewidth=2, color='k',label='normal distribution pdf')\n",
    "    plt.plot(x, pdf2, linewidth=2, color='r',label='t distribution pdf')\n",
    "    plt.xlim(x.min(),x.max())\n",
    "    plt.ylim(0,2)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "interact(compare_distributions,sample_size=(2,20,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The student's t distribution has \"heavier tails\" than the normal distribution. For a sample size greater than $\\approx 20$, the normality assumption is generally accepted as reasonable. \n",
    "\n",
    "In the previous example, $n=51$, which is large enough to assume normality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.5. Types of error in hypothesis testing \n",
    "\n",
    "In hypothesis testing, there are [two types of errors](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors). \n",
    "+ A **type I error** is rejecting the null hypothesis when it is really true (a \"false positive\"). \n",
    "+ A **type II error** is failing to reject the null hypothesis when it is really false (a \"false negative\"). \n",
    "\n",
    "Depending on the application, one type of error can be more consequential than the other. \n",
    "\n",
    "![](InferenceErrors.png)\n",
    "$\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad$ \n",
    "source: [wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)\n",
    "\n",
    "The probability of making a type I (false positive) error is the significance level $\\alpha$ (By definition of $\\alpha$, we allow type I error within $\\alpha$). \n",
    "\n",
    "The probability of making a type II (false negative) error is more difficult to calculate. \n",
    "\n",
    "**Examples**\n",
    "\n",
    "**(1)** In drug testing, we take the null hypothesis $H_0$: \"This drug has no effect on the disease.\" A type I error detects an effect (the drug cures the disease) that is not present. A type II error fails to detect an effect (the drug cures the disease) that is present. \n",
    "\n",
    "**(2)** In a trial, we take the null hypothesis $H_0$: \"This person is innocent.\" A type I error convicts an innocent person. A type II error lets a guilty person go free. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.6. P hacking\n",
    "\n",
    "Recall that the p-value measures how extreme the observation is and is compared to the significance level. Some comments about the p-value:\n",
    "+ A p-value is a probability calculated assuming that $H_0$ is true. \n",
    "+ The smaller the p-value, the stronger the evidence against $H_0$.\n",
    "+ A p-value is not the probability that the null hypothesis is true or false. It is the probability that an erroneous conclusion is reached.\n",
    "\n",
    "Recently the *misuse* of hypothesis testing (p-values) has raised considerable controversy. Basically, if you do enough hypothesis tests, eventually you'll have a Type I (false positive) error. This is sometimes referred to as [Data dredging](https://en.wikipedia.org/wiki/Data_dredging). This is a real problem in a world with tons of data in which it is easy to do many, many hypothesis tests automatically. One method to avoid this is called *cross-validation*, which we'll discuss later. \n",
    "\n",
    "You can read more about 'P hacking' here:\n",
    "\n",
    "- R. Nuzzo, Scientific method: Statistical errors, Nature (2014) [link](https://doi.org/10.1038/506150a)\n",
    "\n",
    "- J. Cohen, The Earth is Round (p<0.05), American Psychologist (1994) [link](https://doi.org/10.1037/0003-066x.49.12.997)\n",
    "\n",
    "- [Planet Money Episode 677: The experiment experiment](https://www.npr.org/sections/money/2018/03/07/591213302/episode-677-the-experiment-experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.7. Confidence intervals\n",
    "\n",
    "A [confidence interval](https://en.wikipedia.org/wiki/Confidence_interval) is an interval estimate for an unknown population parameter. For example, we might use collected data to give an interval estimate for a population mean. \n",
    "\n",
    "### Example: Ergonomic keyboards \n",
    "\n",
    "This example was taken from Devore, pp.277.\n",
    "\n",
    "*Question*: A study is conducted to estimate the preferred height for an experimental keyboard with large forearm-wrist support. A sample of $n=31$ trained typists was selected, and the preferred keyboard height was determined for each typist. The resulting sample average preferred height was $\\bar{X} = 80.0$ cm. Assuming that the preferred height is normally distributed with $\\sigma = 2.0$ cm, obtain a confidence interval for $\\mu$, the true average preferred height for the population of all typists. \n",
    "\n",
    "The CLT tells us that the sample mean $\\bar X$ is normally distributed with expected value $\\mu$ and standard deviation $\\sigma / \\sqrt n$. Standardizing $\\bar X$ by subtracting the expected value and dividing by the standard deviation yields the standard normal variable \n",
    "$$\n",
    "Z = \\frac{\\bar X - \\mu}{\\sigma / \\sqrt n}.\n",
    "$$\n",
    "\n",
    "Since $Z$ is a standard normal variable, and the integral under the standard normal curve between -1.96 and 1.96 is 0.95, we have that (95% confidence interval)\n",
    "$$\n",
    "P( -1.96 < Z < 1.96) = 0.95.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(1.96) - norm.cdf(-1.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's manipulate the inequalities inside the parenthesis:\n",
    "$$\n",
    "-1.96 \\ < \\ \\frac{\\bar X - \\mu}{\\sigma / \\sqrt n} \\ < \\ 1.96.\n",
    "$$\n",
    "This is equivalent to \n",
    "$$\n",
    "\\bar X -1.96 \\frac{\\sigma}{\\sqrt n} \\ < \\ \\mu \\ < \\ \\bar X + 1.96\\frac{\\sigma}{\\sqrt n}, \n",
    "$$\n",
    "which we think of as the interval \n",
    "$$\n",
    "I = \\left( \\bar X -1.96 \\frac{\\sigma}{\\sqrt n}, \\  \\bar X +1.96 \\frac{\\sigma}{\\sqrt n} \\right) \n",
    "$$\n",
    "containing the population mean $\\mu$. \n",
    "The interval can be computed using the sampled data, $I = (79.3, 80.7)$. \n",
    "All together we have \n",
    "$$\n",
    "P\\left( I \\textrm{ contains } \\mu  \\right) = 0.95.\n",
    "$$\n",
    "We say that $I = (79.3, 80.7)$ is the 95% confidence interval for the averaged preferred height. \n",
    "\n",
    "**Comments:**\n",
    "+ A 95% confidence interval means that if we were to repeat the same experiment many times, and compute the confidence interval using the same formula, 95% of the time it would contain the true value of $\\mu$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Two Sample Hypothesis Tests\n",
    "\n",
    "So far we have been concerned with statistical inference from a *single sample*. However it is usually more useful in statistical analysis to compare *two samples* from two different populations or treatment groups. We are interested in whether there is a statistically significant difference between the two populations or treatment groups A and B.\n",
    "\n",
    "If the variable of interest is **quantitative**, we compare the **means** $\\mu_A$, $\\mu_B$ of the two populations. For example:\n",
    "\n",
    "\\begin{align*} \n",
    "H_0: \\mu_A &= \\mu_B \\\\\n",
    "H_A: \\mu_A &\\ne \\mu_B\n",
    "\\end{align*}\n",
    "\n",
    "If the variable of interest is **categorical** with 2 categories, we compare the **proportions** $p_A$, $p_B$ of the two populations. For example:\n",
    "\n",
    "\\begin{align*} \n",
    "H_0: p_A &= p_B \\\\\n",
    "H_A: p_A &\\ne p_B\n",
    "\\end{align*}\n",
    "\n",
    "Here, $\\mu_A, \\mu_B$, $p_A$, $p_B$ appearing in $H_0$ and $H_A$ refer to the **population** parameters. We will evaluate whether there is significant evidence for $H_A$ using the **sample** statistics $\\bar{x}_1$, $\\bar{x}_2$, $\\hat{p}_A$, $\\hat{p}_B$. \n",
    "\n",
    "We'll let $n_A, n_B$ be the sample sizes from populations $A, B$ respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Two sample HT's for means\n",
    "\n",
    "When we have 2 independent samples, we compare the means with a **two sample $t$-test** (this is more robust to small sample sizes than $z$-tests).\n",
    "\n",
    "**Example:** A nursing home records data on the age and gender of its residents who have passed away in the last five years. The ages of the 12 female residents and 10 male residents are given below. Is there significant evidence of a difference in mean age of death for males and females at this nursing home population?\n",
    "\n",
    "Our hypotheses are:\n",
    "\\begin{align*} \n",
    "H_0: \\mu_F &= \\mu_M \\\\\n",
    "H_A: \\mu_F &\\ne \\mu_M\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_death_age = [89, 74, 86, 72, 77, 84, 79, 97, 81, 85, 87, 76]\n",
    "male_death_age = [72, 74, 77, 80, 77, 73, 68, 70, 69, 76]\n",
    "from statistics import stdev\n",
    "print(np.mean(female_death_age))\n",
    "print(stdev(female_death_age)) #sample (not population) standard deviation, different than np.std\n",
    "print(len(female_death_age))\n",
    "print(np.mean(male_death_age))\n",
    "print(stdev(male_death_age))\n",
    "print(len(male_death_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the $t$-test in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "t, pval = ttest_ind(female_death_age, male_death_age,alternative='two-sided')\n",
    "print(t, pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a $p$-value of 0.002 (p value for $H_0$ is small), there is significant evidence of a difference, i.e. females are living longer. If we wanted to run a one-sided test ($H_A: \\mu_F > \\mu_M$), then we would just cut in half the two-sided $p$-value. We also could have run this test using summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind_from_stats\n",
    "t, pval = ttest_ind_from_stats(82.25, 7.149, 12, 73.6, 3.921, 10,alternative='two-sided') \n",
    "#alternatives: â€˜two-sidedâ€™, â€˜lessâ€™, or â€˜greaterâ€™\n",
    "print(t, pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2. Two sample HT's for proportions\n",
    "\n",
    "When we have 2 independent samples of a binary categorical variable, we compare the proportions (i.e. percents) with a two sample $z$-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: 1954 Salk polio-vaccine experiment\n",
    "\n",
    "In 1954, polio was widespread and a new vaccine of unknown efficacy was introduced. To test the efficacy, in a double-blind study, two groups of children were give injections: one contained the vaccine and the other contained a placebo. \n",
    "\n",
    "Let $p_A$ and $p_B$ be the proportions of the children, having received the placebo and vaccine injections, respectively, to contract polio. We formulate the null hypothesis that \n",
    "$$\n",
    "H_0\\colon p_A \\leq p_B,\n",
    "$$\n",
    "that is, the vaccine is not effective.\n",
    "The alternative hypothesis is that \n",
    "$$\n",
    "H_a\\colon p_A  > p_B, \n",
    "$$\n",
    "that is, a vaccinated child is less likely to contract polio than a child receiving the placebo.\n",
    "\n",
    "We choose a significance level of $\\alpha = 0.01$. \n",
    "\n",
    "An experiment was conducted with the following results: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{Placebo:} \\quad N_A = 201,229, \\quad n_A = 110 \\\\\n",
    "&\\text{Vaccine:} \\quad N_B = 200,745, \\quad n_B = 33.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now we perform the hypothesis test and see what the probability of the outcome is under the assumption of the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "counts = [110, 33]\n",
    "sample_sizes = [201229, 200745]\n",
    "z, pval = proportions_ztest(counts, sample_sizes,alternative='larger')\n",
    "#alternative: 'two-sided', 'smaller', or 'larger'\n",
    "print(z, pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If the null hypothesis is true, the probability that we would observe a test statistic this extreme is $6.6\\times10^{-11}$, way less than the significance level, $\\alpha$. We reject the null hypothesis and declare that the vaccine is more effective than a placebo! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation: A/B testing\n",
    "*A/B testing* is a method of comparing two or more versions of an advertisement, webpage, app, etc. We set up an experiment where the variants are shown to users at random and statistical analysis is used to determine which is best. AB testing is the *de facto* test for many business decisions.  \n",
    "\n",
    "**Example.** A/B testing was extensively used by President Obama during his 2008 and 2012 campaigns to  develop \n",
    "* optimized fund-raising strategies,  \n",
    "* get-out-the-vote programs that would be most beneficial, and \n",
    "* target ads to the most susceptible audiences. \n",
    "\n",
    "Learn more here:\n",
    "[Wired story on A/B testing](http://www.wired.com/2012/04/ff_abtesting/)\n",
    "and \n",
    "[Planet Money Episode 669: A or B](https://www.npr.org/sections/money/2015/12/11/459412925/episode-669-a-or-b)\n",
    "\n",
    "**Example.** Suppose your company is developing an advertisement. The art department develops two internet ads: \"Ad A\" and \"Ad B\". Your job is to figure out which is better. \n",
    "\n",
    "You decide to do an experiment: You use Google ads to randomly show 1000 internet users Ad A and 1000 internet users Ad B. \n",
    "\n",
    "It turns out that 500 Ad A viewers click on the ad while 550 Ad B viewers click on the ad? Obviously Ad B did better, but is the difference \"significant\" enough to say that Ad B is better? Or perhaps Ad B just got lucky in this test? \n",
    "\n",
    "In homework 4, youâ€™ll answer this question. More generally, this is a question about the difference between population proportions. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbpresent": {
   "slides": {
    "006f01ca-e160-4faa-ad02-2f873362ca99": {
     "id": "006f01ca-e160-4faa-ad02-2f873362ca99",
     "prev": "e60ea09b-1474-49b0-9ea6-2e803b335693",
     "regions": {
      "88222835-28de-4a0f-895e-303024baf060": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e6a51e7a-d63e-4187-8899-bfbf03f8a4b6",
        "part": "whole"
       },
       "id": "88222835-28de-4a0f-895e-303024baf060"
      }
     }
    },
    "2ba6955d-8be2-4ce3-ae98-f3b3695e4832": {
     "id": "2ba6955d-8be2-4ce3-ae98-f3b3695e4832",
     "prev": "35a7a5a6-f0c3-4b68-9579-e5840160a87d",
     "regions": {
      "63b4b5f3-c348-418c-aabf-932d5fdbcc1c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "883076a7-1c6e-492f-b9d2-0b8550b5c31f",
        "part": "whole"
       },
       "id": "63b4b5f3-c348-418c-aabf-932d5fdbcc1c"
      }
     }
    },
    "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244": {
     "id": "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244",
     "prev": "9ba8c8c8-59a7-4776-84cb-084e5b0a2317",
     "regions": {
      "44582fec-116b-475d-9793-ad29580b7fc2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4992f285-654f-485e-81ef-8a6ae18cad34",
        "part": "whole"
       },
       "id": "44582fec-116b-475d-9793-ad29580b7fc2"
      }
     }
    },
    "35a7a5a6-f0c3-4b68-9579-e5840160a87d": {
     "id": "35a7a5a6-f0c3-4b68-9579-e5840160a87d",
     "prev": "c7291188-b014-4fcb-83bc-f1ea035ee4c9",
     "regions": {
      "cbc80f26-e933-4d90-9dfd-e55a3dc339ba": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "558af430-f4c0-4be9-b1ef-afce5fccd0fa",
        "part": "whole"
       },
       "id": "cbc80f26-e933-4d90-9dfd-e55a3dc339ba"
      }
     }
    },
    "3ecd0fe6-e75f-4362-a6e7-e5273e12058e": {
     "id": "3ecd0fe6-e75f-4362-a6e7-e5273e12058e",
     "prev": "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244",
     "regions": {
      "eac20970-b45c-4073-a596-cdb2a974fe23": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de60c848-d1fb-478d-a736-0ebe21762a24",
        "part": "whole"
       },
       "id": "eac20970-b45c-4073-a596-cdb2a974fe23"
      }
     }
    },
    "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0": {
     "id": "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0",
     "prev": "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066",
     "regions": {
      "ddc97209-2f2f-409d-953c-a9a83dec6738": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "674ee724-0165-40c5-9296-83db8305fa4c",
        "part": "whole"
       },
       "id": "ddc97209-2f2f-409d-953c-a9a83dec6738"
      }
     }
    },
    "95bf00f9-fc2a-4478-bd48-fb66078e061f": {
     "id": "95bf00f9-fc2a-4478-bd48-fb66078e061f",
     "prev": "b9fa7815-a205-4ea6-9076-1289b96670cf",
     "regions": {
      "dd7aef1b-3f05-47a5-bc5f-274809d2c21d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "61e1167e-99ef-4b5d-b717-07a46077a091",
        "part": "whole"
       },
       "id": "dd7aef1b-3f05-47a5-bc5f-274809d2c21d"
      }
     }
    },
    "966d5c12-49ef-4129-aecb-b183804ecd19": {
     "id": "966d5c12-49ef-4129-aecb-b183804ecd19",
     "prev": "3ecd0fe6-e75f-4362-a6e7-e5273e12058e",
     "regions": {
      "ff0704a2-f662-4a03-9874-5613f4634956": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a6fd92a3-b57e-45c5-b216-f9f475baf8ce",
        "part": "whole"
       },
       "id": "ff0704a2-f662-4a03-9874-5613f4634956"
      }
     }
    },
    "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066": {
     "id": "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066",
     "prev": "966d5c12-49ef-4129-aecb-b183804ecd19",
     "regions": {
      "9e037b47-3fb5-4a60-b69c-ad3b282807a1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b79fa570-8c08-4820-a035-2a00bfae1a9b",
        "part": "whole"
       },
       "id": "9e037b47-3fb5-4a60-b69c-ad3b282807a1"
      }
     }
    },
    "9ba8c8c8-59a7-4776-84cb-084e5b0a2317": {
     "id": "9ba8c8c8-59a7-4776-84cb-084e5b0a2317",
     "prev": "9e2b6ffd-bec2-4027-93e8-64b63e770378",
     "regions": {
      "45bb0df9-937a-48a6-882b-346a1253250c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "be5bedf1-b9ed-4caa-bc3e-6c390df97946",
        "part": "whole"
       },
       "id": "45bb0df9-937a-48a6-882b-346a1253250c"
      }
     }
    },
    "9e2b6ffd-bec2-4027-93e8-64b63e770378": {
     "id": "9e2b6ffd-bec2-4027-93e8-64b63e770378",
     "prev": "e9d31a55-0862-44ec-bd48-d74167655985",
     "regions": {
      "7a7c6996-8117-42ce-8093-318b84bd052b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "95b34ac1-b36d-492d-84f9-adafb2d57ace",
        "part": "whole"
       },
       "id": "7a7c6996-8117-42ce-8093-318b84bd052b"
      }
     }
    },
    "ae354c9e-1384-4f31-8e03-5c96f3988bf4": {
     "id": "ae354c9e-1384-4f31-8e03-5c96f3988bf4",
     "prev": null,
     "regions": {
      "9e57ef10-c941-41de-93da-812357c7ec21": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "dac6427e-b8df-46f9-bfd3-b24427a73993",
        "part": "whole"
       },
       "id": "9e57ef10-c941-41de-93da-812357c7ec21"
      }
     }
    },
    "b9fa7815-a205-4ea6-9076-1289b96670cf": {
     "id": "b9fa7815-a205-4ea6-9076-1289b96670cf",
     "prev": "ae354c9e-1384-4f31-8e03-5c96f3988bf4",
     "regions": {
      "cc19ec36-3caa-4666-86e7-2bd1d9cb03b8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c7392535-4666-41a5-a68a-7306dccd6cd8",
        "part": "whole"
       },
       "id": "cc19ec36-3caa-4666-86e7-2bd1d9cb03b8"
      }
     }
    },
    "c7291188-b014-4fcb-83bc-f1ea035ee4c9": {
     "id": "c7291188-b014-4fcb-83bc-f1ea035ee4c9",
     "prev": "006f01ca-e160-4faa-ad02-2f873362ca99",
     "regions": {
      "3fa8900b-1ee2-4625-8e0b-a8a52d95390d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a912604c-786a-448e-a908-397f28b46a13",
        "part": "whole"
       },
       "id": "3fa8900b-1ee2-4625-8e0b-a8a52d95390d"
      }
     }
    },
    "e60ea09b-1474-49b0-9ea6-2e803b335693": {
     "id": "e60ea09b-1474-49b0-9ea6-2e803b335693",
     "prev": "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0",
     "regions": {
      "3df2ec23-ba8a-4b76-b6af-2a4aa219da46": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "06d04c6d-90a4-441d-9d6e-4f719490e12e",
        "part": "whole"
       },
       "id": "3df2ec23-ba8a-4b76-b6af-2a4aa219da46"
      }
     }
    },
    "e9d31a55-0862-44ec-bd48-d74167655985": {
     "id": "e9d31a55-0862-44ec-bd48-d74167655985",
     "prev": "95bf00f9-fc2a-4478-bd48-fb66078e061f",
     "regions": {
      "cc6bd695-e238-4250-8822-ffea3f82f544": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "86c3f014-9535-48f0-95a2-df74d16eaa69",
        "part": "whole"
       },
       "id": "cc6bd695-e238-4250-8822-ffea3f82f544"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
